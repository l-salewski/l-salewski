### Hey ðŸ‘‹

**ðŸŒ±  Currently**:

* [IMPRS-IS](https://imprs.is.mpg.de/) Computer Science PhD Student, currently at the [Explainable Machine Learning Group](https://www.eml-munich.de/#team) and [Computer Graphics Group](https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/computergrafik/computer-graphics/) groups ([University of Tuebingen](https://uni-tuebingen.de/en/)). My supervisors are [Zeynep Akata](https://scholar.google.com/citations?user=jQl9RtkAAAAJ) and [Hendrik Lensch](https://scholar.google.de/citations?user=2R22h84AAAAJ) and my expected graduation date is early 2025.

**ðŸŒ±  Recent Publications**:

* NeurIPS 2023 **Spotlight**: [In-Context Impersonation Reveals Large Language Models' Strengths and Biases](https://arxiv.org/abs/2305.14930).
* NeurIPS 2023 Workshop ML for Audio (**Oral**): [Zero-shot audio captioning with audio-language model guidance and audio context keywords](https://arxiv.org/abs/2311.08396)
* Check out my [Google Scholar](https://scholar.google.de/citations?user=jJz3mXcAAAAJ) and [Semantic Scholar](https://www.semanticscholar.org/author/Leonard-Salewski/151097297) for a full list of my publications.

**ðŸŒ±  Previously**:

* Research Scientist Intern at [NVIDIA](https://www.nvidia.com) with [Ekta Prashnani](https://prashnani.github.io/) and [Joohwan Kim](https://research.nvidia.com/person/joohwan-kim), Santa Clara, US working on integrating actions into vision-language models (2024).
* Research Intern at [Bosch Center for Artifical Intelligence](https://www.bosch-ai.com/) with [Volker Fischer](https://volkerfischer.github.io/), Renningen, Germany working on self-supervised learning for NLP & CV and using transformers for text summarization (2018).

**ðŸŒ±  Technologies**:

* AI: [PyTorch](https://pytorch.org/), [Transformers](https://huggingface.co/docs/transformers/index), [Tokenizers](https://github.com/huggingface/tokenizers), [Tensorflow](https://www.tensorflow.org/), [Keras](https://keras.io/), [Numpy](https://numpy.org/), [Pandas](https://pandas.pydata.org/), [W&B](https://wandb.ai/), [Tensorboard](https://www.tensorflow.org/tensorboard)
* Tooling: [Git](https://git-scm.com/), [SLURM](https://slurm.schedmd.com/documentation.html), [Hydra](https://hydra.cc/), [LangChain](https://github.com/hwchase17/langchain), Linux, [FAISS](https://github.com/facebookresearch/faiss)
* Programming Languages: [Python](python.org), Java, C#, VB.NET, C, C++, [Matlab](https://www.mathworks.com/products/matlab.html)

ðŸ¤” Most of my current work focuses on multi-modal problems such as vision and language as well as explainability and zero-/few-shot learning.

ðŸ“« Reach me for collabs or just general questions [here](mailto:leonard.salewski@uni-tuebingen.de).

<!-- Actual text -->

You can find me on [X](https://x.com/L_Salewski) or [LinkedIn](https://www.linkedin.com/in/leonard-salewski/) - for my research and latest updates, check out my [Google Scholar](https://scholar.google.de/citations?user=jJz3mXcAAAAJ) and [Semantic Scholar](https://www.semanticscholar.org/author/Leonard-Salewski/151097297)!
